<html lang="en">
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VLFHH5CPGM"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-VLFHH5CPGM');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <title>Llm Integration Rails Fastapi Architecture | Software Engineering consultant</title>
  
  <meta name="theme-color">

  <link rel="canonical" href="http://localhost:4000/blog/llm-integration-rails-fastapi-architecture">
  <link rel="alternate" type="application/rss+xml" title="Software Engineering consultant" href="http://localhost:4000/feed.xml" />
  <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Space+Grotesk:wght@400;500;600;700&family=IBM+Plex+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/assets/css/styles.css">
  <meta name="description"
    content="Designing a Production‑Grade LLM Chat Architecture with Ruby on Rails &amp; FastAPI">
  <meta name="keywords"
    content="Software Engineering consultant, programming consultant, Ruby web development, agile Ruby development, Ruby on Rails web design, RoR consulting, Ruby on Rails service, RoR consultant, Ruby on Rails NYC, Ruby on Rails expertise, web agency, ios application development, mobile, api, frontend, backend, development, software engineer partner, sf developer, sf ruby on rails, berling ruby consultant, london consultant">
  <meta name="author" content="Max Lukin">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Llm Integration Rails Fastapi Architecture | Software Engineering consultant</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Llm Integration Rails Fastapi Architecture" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Designing a Production‑Grade LLM Chat Architecture with Ruby on Rails &amp; FastAPI" />
<meta property="og:description" content="Designing a Production‑Grade LLM Chat Architecture with Ruby on Rails &amp; FastAPI" />
<link rel="canonical" href="http://localhost:4000/blog/llm-integration-rails-fastapi-architecture" />
<meta property="og:url" content="http://localhost:4000/blog/llm-integration-rails-fastapi-architecture" />
<meta property="og:site_name" content="Software Engineering consultant" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-12-16T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Llm Integration Rails Fastapi Architecture" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-12-16T00:00:00+00:00","datePublished":"2025-12-16T00:00:00+00:00","description":"Designing a Production‑Grade LLM Chat Architecture with Ruby on Rails &amp; FastAPI","headline":"Llm Integration Rails Fastapi Architecture","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/llm-integration-rails-fastapi-architecture"},"url":"http://localhost:4000/blog/llm-integration-rails-fastapi-architecture"}</script>
<!-- End Jekyll SEO tag -->

</head>


  <body class="max-w-4xl mx-auto py-4 md:py-8 px-4 sm:px-6 lg:px-8 bg-[#c2c5aa]">
    <header>
      &nbsp;
    </header>

    <main>
      <article class="w-full">
  <!-- Navigation -->
  <nav class="mb-8">
    <div class="flex items-center justify-between">
      <a href="/blog" class="no-underline text-[#656d4a] hover:text-[#333d29] transition-colors flex items-center gap-2 group">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 24 24" stroke="currentColor" class="group-hover:-translate-x-1 transition-transform">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"/>
        </svg>
        <span class="font-medium">All Posts</span>
      </a>
      <a href="/" class="no-underline text-[#333d29] hover:text-[#333d29] opacity-80 transition-colors flex items-center gap-2">
        <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="none" viewBox="0 0 16 16">
          <path d="M8 4.5l-4 3.5V12a1 1 0 0 0 1 1h2.5v-2.5h1V13H11a1 1 0 0 0 1-1V8l-4-3.5z" fill="currentColor"/>
          <path d="M2 8l6-5 6 5" stroke="currentColor" stroke-width="1.2" fill="none"/>
        </svg>
        <span class="text-sm">Home</span>
      </a>
    </div>
  </nav>

  <!-- Post header -->
  <header class="mb-8 pb-8 border-b border-[#b6ad90]">
    <h1 class="font-display text-3xl md:text-4xl lg:text-5xl font-bold text-[#333d29] mb-4 leading-tight">
      Llm Integration Rails Fastapi Architecture
    </h1>
    <div class="flex items-center gap-4 text-[#333d29] opacity-80">
      <time class="text-sm font-medium">December 16, 2025</time>
      
    </div>
  </header>

  <!-- Post content -->
  <div class="prose prose-lg max-w-none">
    
<h1 id="designing-a-productiongrade-llm-chat-architecture-with-ruby-on-rails--fastapi">Designing a Production‑Grade LLM Chat Architecture with Ruby on Rails &amp; FastAPI</h1>

<blockquote>
  <p><strong>Audience</strong>: Senior backend engineers, tech leads, architects<br />
<strong>Scope</strong>: End‑to‑end architecture, security, performance, streaming, async processing, and real‑world trade‑offs<br />
<strong>Stack</strong>: Ruby on Rails API + FastAPI (Python) + Next.js frontend<br />
<strong>Terminology</strong>: “LLM” refers to any Large Language Model backend (OpenAI, Anthropic, self‑hosted, etc.)</p>
</blockquote>

<hr />

<h2 id="1-why-llm-integration-is-not-just-add-a-chat-endpoint">1. Why LLM integration is <em>not</em> just “add a chat endpoint”</h2>

<p>Adding an LLM to a production system introduces <strong>new architectural dimensions</strong>:</p>

<ul>
  <li>Long‑lived connections (streaming)</li>
  <li>Token‑based billing &amp; metering</li>
  <li>Session state that spans services</li>
  <li>Mixed latency profiles (milliseconds vs seconds)</li>
  <li>Security boundaries between app code and AI code</li>
  <li>Failure modes that didn’t exist before</li>
</ul>

<p>This article shows <strong>how to integrate LLM chat correctly</strong>, without breaking your existing Rails architecture.</p>

<hr />

<h2 id="2-baseline-system-assumptions">2. Baseline system assumptions</h2>

<p>We assume a mature Rails API with:</p>

<ul>
  <li>Devise + JWT authentication</li>
  <li>Pundit authorization</li>
  <li>Centralized billing / credits</li>
  <li>Redis + Sidekiq</li>
  <li>ActionCable available</li>
  <li>Next.js frontend</li>
  <li>A dedicated FastAPI service that:
    <ul>
      <li>Runs LLM inference</li>
      <li>Handles embeddings / vector search</li>
      <li>Stores conversation state (e.g. MongoDB)</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="3-integration-patterns-overview">3. Integration patterns overview</h2>

<h3 id="option-a--rails-api-gateway-recommended-starting-point">Option A — Rails API Gateway (Recommended starting point)</h3>

<p><strong>Rails is the single public entry point.</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Frontend → Rails API → FastAPI (internal)
</code></pre></div></div>

<p>Rails handles:</p>
<ul>
  <li>Auth &amp; authorization</li>
  <li>Billing &amp; credits</li>
  <li>Input validation</li>
  <li>Auditing</li>
  <li>Session ownership</li>
</ul>

<p>FastAPI focuses only on:</p>
<ul>
  <li>LLM logic</li>
  <li>Intent classification</li>
  <li>Vector search</li>
  <li>Streaming tokens</li>
</ul>

<p><strong>Best for</strong></p>
<ul>
  <li>Security‑first systems</li>
  <li>Centralized billing</li>
  <li>Small to medium scale</li>
  <li>Teams already invested in Rails</li>
</ul>

<p><strong>Trade‑off</strong></p>
<ul>
  <li>+1 network hop (~30–50ms)</li>
  <li>Rails threads involved in streaming</li>
</ul>

<hr />

<h3 id="option-b--shared-jwt--direct-access">Option B — Shared JWT / Direct Access</h3>

<p><strong>Frontend talks directly to FastAPI for LLM calls.</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Frontend → Rails (auth, token)
Frontend → FastAPI (LLM, streaming)
</code></pre></div></div>

<p>Rails issues short‑lived <strong>LLM tokens</strong> (JWT).</p>

<p><strong>Best for</strong></p>
<ul>
  <li>Ultra‑low latency streaming</li>
  <li>100+ concurrent streams</li>
  <li>Independent LLM scaling</li>
</ul>

<p><strong>Trade‑off</strong></p>
<ul>
  <li>FastAPI becomes public</li>
  <li>JWT secret sharing</li>
  <li>Post‑facto billing via webhooks</li>
</ul>

<hr />

<h3 id="option-c--service-mesh-istio--linkerd">Option C — Service Mesh (Istio / Linkerd)</h3>

<p><strong>Infrastructure handles auth, routing, retries.</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Frontend → Istio → Rails / FastAPI
</code></pre></div></div>

<p><strong>Best for</strong></p>
<ul>
  <li>Kubernetes‑native teams</li>
  <li>Zero‑trust networking</li>
  <li>Built‑in tracing (Jaeger, Prometheus)</li>
</ul>

<p><strong>Trade‑off</strong></p>
<ul>
  <li>High infra complexity</li>
  <li>Overkill for 2–3 services</li>
</ul>

<hr />

<h3 id="option-d--message-queue-async--batch">Option D — Message Queue (Async / Batch)</h3>

<p><strong>Non‑interactive LLM workloads.</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Frontend → Rails → Queue → FastAPI Workers
</code></pre></div></div>

<p>Results delivered via:</p>
<ul>
  <li>Webhooks</li>
  <li>Polling</li>
  <li>ActionCable</li>
</ul>

<p><strong>Best for</strong></p>
<ul>
  <li>Batch analysis</li>
  <li>“Analyze 500 profiles”</li>
  <li>Long‑running jobs</li>
</ul>

<p><strong>Not suitable for</strong></p>
<ul>
  <li>Interactive chat UX</li>
</ul>

<hr />

<h2 id="4-streaming-architecture-sse">4. Streaming architecture (SSE)</h2>

<h3 id="why-sse-not-websockets">Why SSE (not WebSockets)?</h3>

<ul>
  <li>Simple</li>
  <li>HTTP‑native</li>
  <li>Works well with proxies</li>
  <li>Perfect for token streams</li>
</ul>

<h3 id="streaming-flow-option-a">Streaming flow (Option A)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Frontend ──► Rails (SSE)
              └──► FastAPI (SSE)
FastAPI streams tokens
Rails forwards tokens
Frontend renders incrementally
</code></pre></div></div>

<h3 id="rails-streaming-controller-simplified">Rails streaming controller (simplified)</h3>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LlmStreamsController</span> <span class="o">&lt;</span> <span class="no">ApplicationController</span>
  <span class="kp">include</span> <span class="no">ActionController</span><span class="o">::</span><span class="no">Live</span>

  <span class="k">def</span> <span class="nf">stream</span>
    <span class="n">response</span><span class="p">.</span><span class="nf">headers</span><span class="p">[</span><span class="s2">"Content-Type"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"text/event-stream"</span>
    <span class="n">response</span><span class="p">.</span><span class="nf">headers</span><span class="p">[</span><span class="s2">"Cache-Control"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"no-cache"</span>
    <span class="n">response</span><span class="p">.</span><span class="nf">headers</span><span class="p">[</span><span class="s2">"X-Accel-Buffering"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"no"</span>

    <span class="n">sse</span> <span class="o">=</span> <span class="no">SSE</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="nf">stream</span><span class="p">)</span>

    <span class="no">FastapiStreamingClient</span><span class="p">.</span><span class="nf">stream</span><span class="p">(</span><span class="ss">query: </span><span class="n">params</span><span class="p">[</span><span class="ss">:query</span><span class="p">])</span> <span class="k">do</span> <span class="o">|</span><span class="n">chunk</span><span class="o">|</span>
      <span class="n">sse</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">ensure</span>
    <span class="n">sse</span><span class="p">.</span><span class="nf">close</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h3 id="fastapi-streaming-endpoint">FastAPI streaming endpoint</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@router.post</span><span class="p">(</span><span class="sh">"</span><span class="s">/chat/stream</span><span class="sh">"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">stream_chat</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">ChatRequest</span><span class="p">):</span>
    <span class="k">async</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">llm</span><span class="p">.</span><span class="nf">stream</span><span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">query</span><span class="p">):</span>
        <span class="k">yield</span> <span class="sa">f</span><span class="sh">"</span><span class="s">data: </span><span class="si">{</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="si">{</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="si">:</span> <span class="n">token</span><span class="si">}</span><span class="p">)</span><span class="si">}</span><span class="se">\n\n</span><span class="sh">"</span>
</code></pre></div></div>

<hr />

<h2 id="5-session-management-crossservice">5. Session management (cross‑service)</h2>

<p><strong>Rule</strong>: Only one system owns session state.</p>

<p>Recommended:</p>
<ul>
  <li>FastAPI owns conversation history (MongoDB)</li>
  <li>Rails mirrors minimal session metadata:
    <ul>
      <li>session_id</li>
      <li>last_activity_at</li>
      <li>credits_used</li>
      <li>user_id / company_id</li>
    </ul>
  </li>
</ul>

<p>Rails never reconstructs chat history — it <strong>queries FastAPI</strong>.</p>

<hr />

<h2 id="6-billing--credit-safety">6. Billing &amp; credit safety</h2>

<h3 id="option-a-gateway">Option A (Gateway)</h3>

<ul>
  <li>Credits checked <strong>before</strong> request</li>
  <li>Deducted synchronously</li>
  <li>Request fails if insufficient</li>
</ul>

<h3 id="option-b-direct">Option B (Direct)</h3>

<ul>
  <li>FastAPI reports usage via webhook</li>
  <li>Rails reconciles asynchronously</li>
  <li>Periodic reconciliation job required</li>
</ul>

<h3 id="option-d-queue">Option D (Queue)</h3>

<ul>
  <li>Credits reserved upfront</li>
  <li>Released or finalized on completion</li>
</ul>

<hr />

<h2 id="7-error-handling-strategy">7. Error handling strategy</h2>

<table>
  <thead>
    <tr>
      <th>Scenario</th>
      <th>Strategy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>No results</td>
      <td>Friendly LLM response</td>
    </tr>
    <tr>
      <td>Invalid filters</td>
      <td>Structured validation error</td>
    </tr>
    <tr>
      <td>FastAPI timeout</td>
      <td>504 + retry advice</td>
    </tr>
    <tr>
      <td>Session not found</td>
      <td>Graceful fallback</td>
    </tr>
    <tr>
      <td>Streaming disconnect</td>
      <td>Safe cleanup</td>
    </tr>
    <tr>
      <td>LLM crash</td>
      <td>Circuit breaker / retry</td>
    </tr>
  </tbody>
</table>

<p>Always attach:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">request_id</code></li>
  <li><code class="language-plaintext highlighter-rouge">session_id</code></li>
  <li><code class="language-plaintext highlighter-rouge">response_time_ms</code></li>
</ul>

<hr />

<h2 id="8-security-boundaries">8. Security boundaries</h2>

<h3 id="do">Do</h3>
<ul>
  <li>Keep FastAPI private if possible</li>
  <li>Validate all inputs in Rails</li>
  <li>Use short‑lived tokens</li>
  <li>Log usage, not prompts</li>
  <li>Enforce scopes</li>
</ul>

<h3 id="avoid">Avoid</h3>
<ul>
  <li>Exposing raw LLM APIs publicly</li>
  <li>Sharing long‑lived secrets</li>
  <li>Letting frontend call OpenAI directly</li>
  <li>Mixing billing logic into FastAPI</li>
</ul>

<hr />

<h2 id="9-decision-matrix">9. Decision matrix</h2>

<table>
  <thead>
    <tr>
      <th>Requirement</th>
      <th>Best Option</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Fastest time‑to‑market</td>
      <td>Option A</td>
    </tr>
    <tr>
      <td>Best streaming performance</td>
      <td>Option B</td>
    </tr>
    <tr>
      <td>Best security</td>
      <td>Option A / C</td>
    </tr>
    <tr>
      <td>Kubernetes native</td>
      <td>Option C</td>
    </tr>
    <tr>
      <td>Batch workloads</td>
      <td>Option D</td>
    </tr>
    <tr>
      <td>Hybrid system</td>
      <td>A + D</td>
    </tr>
    <tr>
      <td>Future‑proof</td>
      <td>A → Hybrid → B</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="10-recommended-evolution-path">10. Recommended evolution path</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Start: Option A (Gateway)
↓
Add Option D for batch jobs
↓
If streaming becomes bottleneck:
→ Hybrid (Rails auth + FastAPI streaming)
↓
If scale demands:
→ Option B or Service Mesh
</code></pre></div></div>

<hr />

<h2 id="11-key-takeaway">11. Key takeaway</h2>

<p><strong>LLM integration is a system design problem, not a controller problem.</strong></p>

<p>If you:</p>
<ul>
  <li>Centralize auth</li>
  <li>Treat streaming as first‑class</li>
  <li>Separate billing from inference</li>
  <li>Respect service boundaries</li>
</ul>

<p>…you get an AI feature that <strong>scales with your product</strong>, not against it.</p>

<hr />

<h2 id="appendix">Appendix</h2>

<ul>
  <li>SSE vs WebSockets comparison</li>
  <li>JWT vs OAuth trade‑offs</li>
  <li>Credit reconciliation strategies</li>
  <li>Observability checklists</li>
</ul>

<hr />

<p><em>Author: Engineering Architecture Notes</em><br />
<em>Last updated: 2025</em></p>

  </div>

  <!-- Post footer -->
  <footer class="mt-12 pt-8 border-t border-[#b6ad90]">
    <a href="/blog" class="no-underline text-[#656d4a] hover:text-[#333d29] transition-colors flex items-center gap-2 group inline-flex">
      <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 24 24" stroke="currentColor" class="group-hover:-translate-x-1 transition-transform">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"/>
      </svg>
      <span class="font-medium">Back to all posts</span>
    </a>
  </footer>
</article>

    </main>

    <footer>
      <div class="flex justify-center p-2 m-2">
  <a href="https://lukin.io/cv.pdf" target="_blank" title="Download CV" class="no-underline flex items-center gap-2">
    <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 20 20">
      <g>
        <!-- File outline -->
        <rect x="3" y="2" width="14" height="16" rx="2" fill="none" stroke="currentColor" stroke-width="1.5"/>
        <!-- Down arrow for download -->
        <path d="M10 7v6m0 0l-2.5-2.5M10 13l2.5-2.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" fill="none"/>
        <!-- Download bar -->
        <rect x="8" y="15" width="4" height="1.2" rx="0.6" fill="currentColor"/>
      </g>
    </svg>
    <span class="font-medium text-[1.05em] text-current tracking-wide">Download CV</span>
  </a>
</div>

    </footer>
  </body>

</html>
